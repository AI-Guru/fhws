{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Add colab button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Dr. Tristan Behrens\n",
    "## Today: End to End Learning for Self-Driving Cars.\n",
    "\n",
    "<img src=\"https://ai-guru.s3.eu-central-1.amazonaws.com/FHWS/demo.gif\" alt=\"Drawing\" style=\"width:400px; margin-left:0\" />\n",
    "\n",
    "Paper: https://arxiv.org/abs/1604.07316  \n",
    "Dataset: https://www.kaggle.com/roydatascience/training-car\n",
    "\n",
    "What is the paper about?\n",
    "\n",
    "- Nvidia.\n",
    "- Training CNN on raw pixels.\n",
    "- One camera mapped to steering commands.\n",
    "- 72 hours of training data from two cars. ???\n",
    "- No explicit decomposition of the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_data_path = \"training-car-unprocessed.p\"\n",
    "data_path = \"training-car.p\"\n",
    "\n",
    "if os.path.exists(unprocessed_data_path) == False:\n",
    "    !wget https://ai-guru.s3.eu-central-1.amazonaws.com/FHWS/training-car-unprocessed.p\n",
    "else:\n",
    "    print(\"Data already downloaded.\")\n",
    "        \n",
    "if os.path.exists(data_path) == False:\n",
    "    !wget https://ai-guru.s3.eu-central-1.amazonaws.com/FHWS/training-car.p\n",
    "else:\n",
    "    print(\"Data already downloaded.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load and inspect unprocessed data.\n",
    "\n",
    "Firstly, we define a method for rendering random samples from any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_random_samples(images, targets):\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        _, _ = plt.subplots(1, 3, figsize=(15,15))\n",
    "\n",
    "        subplot_index = 1\n",
    "        for j in np.random.choice(list(range(len(images))), 3):\n",
    "\n",
    "            image = images[j] / 255.0\n",
    "            target = targets[j]\n",
    "            plt.subplot(1, 3, subplot_index)\n",
    "            plt.imshow(image, cmap=\"gray\")\n",
    "            plt.title(\"Steering {:0.2f}\".format(target))\n",
    "            subplot_index += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Then we load the unpropressed data. Note: Not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file.\n",
    "with open(unprocessed_data_path, \"rb\") as file:\n",
    "    images_unprocessed, targets_unprocessed = pickle.load(file)\n",
    "print(images_unprocessed.shape)\n",
    "print(targets_unprocessed.shape)\n",
    "\n",
    "render_random_samples(images_unprocessed, targets_unprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. About data preprocessing.\n",
    "\n",
    "Steps:\n",
    "1. Load image.\n",
    "2. Convert to [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV).\n",
    "3. Discard H and S. Keep only V.\n",
    "4. Resize to 40x40.\n",
    "\n",
    "Preprocessing happened offline. See preprocessing notebook for details. Try at home.\n",
    "\n",
    "**Questions**: \n",
    "- Why preprocessing?\n",
    "- Especially: Why downscaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Load and inspect preprocessed data.\n",
    "\n",
    "This is the data we will use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"rb\") as file:\n",
    "    images, targets = pickle.load(file)\n",
    "print(images.shape)\n",
    "print(targets.shape)\n",
    "\n",
    "render_random_samples(images, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Render distribution of targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min:\", np.min(targets))\n",
    "print(\"Mean:\", np.mean(targets))\n",
    "print(\"STD:\", np.std(targets))\n",
    "print(\"Max:\", np.max(targets))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(targets, bins=75)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Is there a problem with this distribution?\n",
    "- Is there a problem with the dataset size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Designing and training a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Neural Network architecture.\n",
    "\n",
    "- Lambda: Apply a function.\n",
    "- Reshape: Change dimensions.\n",
    "- Conv2D: Applying multiple filters on all possible locations.\n",
    "- MaxPooling2D: Downsampling with maximum function.\n",
    "- Flatten: Go down to one dimension.\n",
    "- Dropout: Randomly set inputs to zero.\n",
    "- BatchNormalization: Normalize inputs using mean and STD.\n",
    "- Dense: Fully-connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Lambda(lambda image: image / 127.5 - 1., input_shape=(40, 40)))\n",
    "model.add(layers.Reshape((40, 40, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Compilation adds optimizer, loss and metrics.\n",
    "\n",
    "- Nadam: Adam with Nesterov momentum.\n",
    "- MSE: Mean squared error.\n",
    "- MAE: Mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Nadam(lr=0.0001), \n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate model quality (before training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render a random image, the target, the prediction and the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sample():\n",
    "    random_index = random.randint(0, len(images) - 1)\n",
    "    image = images[random_index]\n",
    "    target = targets[random_index]\n",
    "    predicted_target = model.predict(np.array([image]))[0][0]\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    error = np.abs(target - predicted_target)\n",
    "    plt.title(\"Predicted: {:0.2f} Expected: {:0.2f} Error: {:0.2f}\".format(predicted_target, target, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Get the error(s) for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = model.evaluate(images, targets)\n",
    "print(\"MSE: {:0.2f}\".format(mse))\n",
    "print(\"MAE: {:0.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Visualize how well the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_predictions():\n",
    "    expected_targets = []\n",
    "    predicted_targets = []\n",
    "    for i in tqdm(range(0, 1000, 3)):\n",
    "        image = images[i]\n",
    "        expected_target = targets[i]\n",
    "        predicted_target = model.predict(np.array([image]))[0][0]\n",
    "        expected_targets.append(expected_target)\n",
    "        predicted_targets.append(predicted_target)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-0.5, 0.5])\n",
    "    plt.plot(expected_targets, label=\"Expected\")\n",
    "    plt.plot(predicted_targets, label=\"Predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    images, targets,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Render the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE.\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# MAE.\n",
    "if \"mae\" in history.history:\n",
    "    plt.plot(history.history[\"mae\"], label=\"mae\")\n",
    "    plt.plot(history.history[\"val_mae\"], label=\"val_mae\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "elif \"mean_absolute_error\" in history.history:\n",
    "    plt.plot(history.history[\"mean_absolute_error\"], label=\"mean_absolute_error\")\n",
    "    plt.plot(history.history[\"val_mean_absolute_error\"], label=\"val_mean_absolute_error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- What do we see here?\n",
    "- How good is the Neural Network?\n",
    "- Which plot is the most important one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Evaluate model quality (after training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render a random image, the target, the prediction and the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Get the error(s) for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = model.evaluate(images, targets)\n",
    "print(\"MSE: {:0.2f}\".format(mse))\n",
    "print(\"MAE: {:0.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Visualize how well the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "render_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary and outlook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "- Convolutional Neural Networks can solve Autonomous Driving.\n",
    "- Input comes from camera, output is steering.\n",
    "- A lot of data is necessary.\n",
    "    \n",
    "Outlook:\n",
    "\n",
    "- Train on way more data.\n",
    "- Have a closer look at how convolutions and pooling-layers work.\n",
    "- Train on more steering, throttle and brake.\n",
    "- [Autonomous Drone Navigation with Deep Learning](https://www.youtube.com/watch?v=H7Ym3DMSGms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References.\n",
    "\n",
    "- https://www.manning.com/books/deep-learning-with-python\n",
    "- https://www.deeplearningbook.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
